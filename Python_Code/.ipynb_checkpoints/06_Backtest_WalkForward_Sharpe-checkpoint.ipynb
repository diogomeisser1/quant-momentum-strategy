{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0942a89d-3574-480d-859e-dd559d2c765c",
   "metadata": {},
   "source": [
    "Introducing Sharpe Ratio: Sharpe Ratio= (μ−rf)/σ  where u is the return, rf is the risk free rate and Sigma is the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad52cb9-0c07-4244-8734-7e5fab71c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf  \n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5662c-7e8e-408a-aef6-ddff0e19fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "log_returns = pd.read_csv('DATA/ETF_log_returns.csv', index_col='Date', parse_dates=True)\n",
    "adj_close_price = pd.read_csv('DATA/ETF_ADJ_close_returns.csv', index_col='Date', parse_dates=True)\n",
    "# Check it loaded:\n",
    "# log_returns\n",
    "# close_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0670b-13b3-4e1d-9fd5-dd4bd051807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign etf vector\n",
    "etfs = ['DIA','SPY','QQQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe147116-389f-4bc3-be3c-e40269f218b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_crossover(\n",
    "    etfs,\n",
    "    log_returns,\n",
    "    short_ma,\n",
    "    long_ma,\n",
    "    threshold=0.0,\n",
    "    initial_position=0\n",
    "):\n",
    "    log_return_summary = {}  # Dictionary to store results\n",
    "\n",
    "    for etf in etfs:\n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'log_return': log_returns[etf],\n",
    "            'short_ma': short_ma[etf],\n",
    "            'long_ma': long_ma[etf]\n",
    "        }).dropna()\n",
    "\n",
    "        # Raw signals (before filtering)\n",
    "        df['entry_signal'] = (\n",
    "            (df['short_ma'] > df['long_ma'] * (1 + threshold)) &\n",
    "            (df['short_ma'].shift(1) <= df['long_ma'].shift(1))\n",
    "        )\n",
    "\n",
    "        df['exit_signal'] = (\n",
    "            (df['short_ma'] < df['long_ma'] * (1 - threshold)) &\n",
    "            (df['short_ma'].shift(1) >= df['long_ma'].shift(1))\n",
    "        )\n",
    "\n",
    "        # Filter signals based on position\n",
    "        position = initial_position  # <-- FIXED: use initial position\n",
    "        entry_mask = []\n",
    "        exit_mask = []\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            if df['entry_signal'].iloc[i] and position == 0:\n",
    "                entry_mask.append(True)\n",
    "                exit_mask.append(False)\n",
    "                position = 1\n",
    "            elif df['exit_signal'].iloc[i] and position == 1:\n",
    "                entry_mask.append(False)\n",
    "                exit_mask.append(True)\n",
    "                position = 0\n",
    "            else:\n",
    "                entry_mask.append(False)\n",
    "                exit_mask.append(False)\n",
    "\n",
    "        df['entry_signal'] = entry_mask\n",
    "        df['exit_signal'] = exit_mask\n",
    "\n",
    "        # Explicit position tracking using updated signals\n",
    "        position_list = []\n",
    "        current_position = initial_position\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            if df['entry_signal'].iloc[i] and current_position == 0:\n",
    "                current_position = 1\n",
    "            elif df['exit_signal'].iloc[i] and current_position == 1:\n",
    "                current_position = 0\n",
    "            position_list.append(current_position)\n",
    "\n",
    "        df['position'] = position_list\n",
    "\n",
    "        # Shift position to avoid lookahead bias\n",
    "        df['shifted_position'] = df['position'].shift(1)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # Strategy returns\n",
    "        df['strategy_log_return'] = df['shifted_position'] * df['log_return']\n",
    "\n",
    "        # Metrics\n",
    "        trade_count = df['entry_signal'].sum() + df['exit_signal'].sum()\n",
    "        mean_return = df['strategy_log_return'].mean()\n",
    "        std_return = df['strategy_log_return'].std()\n",
    "        sharpe_ratio = mean_return / std_return if std_return > 0 else 0\n",
    "\n",
    "        log_return_summary[etf] = {\n",
    "            'Total Strategy Return': np.exp(df['strategy_log_return'].sum()) - 1,\n",
    "            'Trade Count': int(trade_count),\n",
    "            'Sharpe': sharpe_ratio\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(log_return_summary).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306146f0-f91a-4e60-82eb-b5b026e5f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_sharp(adj_close_price, log_returns, etfs, train_years=3, test_years=2):\n",
    "    #creating a function that will loop long and short_ma combinations on various thresholds to find optimal returns on training years \n",
    "    #and then compare performance on testing years. Walk forward split 2yrs-training and then 1yr-testing for entireity of the dataset\n",
    "    walk_results = []\n",
    "    #creating an empty list to store results\n",
    "\n",
    "    # Threshold search space\n",
    "    #creating a vector list of thresholds. from 0 to .005 jumping by .00025 and rounding to 5 decimal points\n",
    "    thresholds = np.round(np.arange(0.0, 0.005, 0.00025), 5)\n",
    "\n",
    "    # Get full date range\n",
    "    #finding the entirity date length of the dataset using index of adjusted closing prices(row labels - dates0\n",
    "    full_dates = adj_close_price.index #will give all the dates\n",
    "    start_year = full_dates.min().year #will find the minimum date - the earliest date - furthest back\n",
    "    end_year = full_dates.max().year #will find the latest date in the dataset\n",
    "\n",
    "    for start in range(start_year, end_year - train_years - test_years + 1): #creating a range  (x-y) for each starting year \n",
    "        #meaning a range for 1999-2022 and then for 2000 - 2022 and so on... end year is subtracted by training years and test years but we \n",
    "        #add one because range(a,b) the a is inclusive and b is exclusive meaning not included in the calculation meaning the last year is cutoff\n",
    "        #basically saying that for every number in this range do the following(exclusive of end value)\n",
    "        \n",
    "        # 1. Define calendar-aware train/test windows\n",
    "        train_start = pd.Timestamp(f\"{start}-01-01\") #use timestamp from pandas library storing the starting date for each range loop\n",
    "        #turns the string into a datetime object for arithmetic calculations\n",
    "        train_end   = train_start + pd.DateOffset(years=train_years) - pd.Timedelta(days=1)\n",
    "        # the dateoffset is adding exactly training years to the timestamp =2yrs and the timedelta is subtracting 1 day so we land on 12-31\n",
    "        test_start  = train_end + pd.Timedelta(days=1)\n",
    "        #the test start adds a day so we land on the 1st of the year again\n",
    "        test_end    = test_start + pd.DateOffset(years=test_years) - pd.Timedelta(days=1)\n",
    "        #the test end is getting the test years added which is 1yr and subtracting 1 day again so we land on 12-31\n",
    "#Use Case\tRecommended Function\tWhy?\n",
    "# Add/subtract days\tpd.Timedelta(days=...)\tExact time math\n",
    "# Add/subtract weeks\tpd.Timedelta(weeks=...)\tExact, consistent\n",
    "# Add/subtract months\tpd.DateOffset(months=...)\tHandles month length variation\n",
    "# Add/subtract years\tpd.DateOffset(years=...)\tHandles leap years, calendar logic\n",
    "# logic here is that dateoffset can also subtract but would have to use negative value so visually better to use Timedelta also when subtracting\n",
    "\n",
    "        # 2. Slice training data\n",
    "        adj_train = adj_close_price.loc[train_start:train_end]\n",
    "#slicing data so that we have the adj_train assigned to the rows from training start to training end. both inclusive \n",
    "        log_train = log_returns.loc[train_start:train_end]\n",
    "        #getting log_test\n",
    "        log_test = log_returns.loc[test_start:test_end]\n",
    "        #getting adj_test\n",
    "        adj_test = adj_close_price.loc[test_start:test_end]\n",
    "\n",
    "\n",
    "        # 3. Grid search for best strategy parameters\n",
    "        results = [] #creating an empty list for results for the best short and long_ma combination\n",
    "        for short in range(10, 100, 5): # Loop through all short moving average windows from 5 to 49 (inclusive)\n",
    "            for long in range(short + 10, 255, 5):# For each short MA do a loop through x+1 to 50 and do the following for each\n",
    " \n",
    "                short_ma = adj_train.rolling(short).mean() #create a rolling average\n",
    "                long_ma = adj_train.rolling(long).mean()\n",
    "                short_df = pd.DataFrame(short_ma, index=adj_train.index, columns=adj_train.columns) #create a dataframe (ensure consinstency)\n",
    "                long_df = pd.DataFrame(long_ma, index=adj_train.index, columns=adj_train.columns)\n",
    "\n",
    "                for threshold in thresholds: \n",
    "# For every short_ma value from 5 to 49,\n",
    "# try every possible long_ma value that is larger than short_ma (from short_ma+1 to 50).\n",
    "# For each (short_ma, long_ma) pair, loop through all threshold values from 0.0 to 0.005, stepping by 0.00025.\n",
    "# This way, we try every combination of short MA, long MA, and threshold to find the best-performing set.\n",
    "\n",
    "                    print(f\"Training Year: {start}, Short: {short}, Long: {long}, Threshold: {threshold}\", end=\"\\r\")\n",
    "                    sys.stdout.flush() #end=\"\\r\"tells Python not to move to a new line after printing.next print() to overwrite the same line\n",
    "                    #the sys.stdout.flush() basically forces out output meaning it gets rid of any buffer or anything that python might have to print output\n",
    "\n",
    "                    summary = ma_crossover(\n",
    "                        etfs, log_train, short_df, long_df, threshold\n",
    "                    ) #run this combination through our strategy function define above \n",
    "\n",
    "                    MIN_TRADES = 4\n",
    "\n",
    "                    for etf in etfs: \n",
    "                        trade_count = summary.loc[etf, 'Trade Count']\n",
    "\n",
    "                        if trade_count >= MIN_TRADES:\n",
    "                        #and for every etf defined earlier as ['DIA,'SPY','QQQ'] append adding an element to the end of a list and add the following \n",
    "                            results.append({ #{ = dict.\n",
    "                                'ETF': etf,  #defining dictionary terms meaning we are adding a dictionary into a list with key 'ETF' (STRING) and value of the ETF = 'QQQ'\n",
    "                                'Short_MA': short,\n",
    "                                'Long_MA': long,\n",
    "                                'Threshold': threshold,\n",
    "                                'Return': summary.loc[etf, 'Total Strategy Return'],\n",
    "                                'Trade Count': summary.loc[etf, 'Trade Count'],\n",
    "                                'Sharpe': summary.loc[etf, 'Sharpe']  # NEW: Store Sharpe\n",
    "                            })\n",
    "\n",
    "        # 4. Select best config per ETF\n",
    "        results_df = pd.DataFrame(results) #turning  the giant dictionary into a dataframe. keys become columns and values become rows\n",
    "        best_ma = results_df.sort_values('Sharpe', ascending=False).groupby('ETF').first()  # NEW: Sort by Sharpe\n",
    "        #now we sort by return and then group by ETF and then take the first row for eahc which is the highest return \n",
    "        #this is inside the training year loop so it is doing this for every individual training period \n",
    "\n",
    "        # 5. Apply best strategy on the test set and apply a buffer\n",
    "        buffer_days = 400 \n",
    "        #assigning buffer to 400 days \n",
    "        test_start_buffered = test_start - pd.Timedelta(days=buffer_days) #subtracting buffer days from test set to go back 400 days \n",
    "        adj_test_buffered = adj_close_price.loc[test_start_buffered:test_end] #snip the following rows from adjusted close from 400 back from test period to end of test period\n",
    "\n",
    "        for etf in etfs: #now for the best paramaters for that testing period for each etf do the following \n",
    "            short = int(best_ma.loc[etf, 'Short_MA']) #assign short_ma value to short variable\n",
    "            long = int(best_ma.loc[etf, 'Long_MA'])\n",
    "            threshold = best_ma.loc[etf, 'Threshold']\n",
    "\n",
    "            # Rolling averages on buffered data\n",
    "            short_ma = adj_test_buffered[etf].rolling(short).mean() #calculate the rolling average using paramaters from testing period but applying \n",
    "            #to the buffered testing period (includes 400 days back)\n",
    "            long_ma = adj_test_buffered[etf].rolling(long).mean() #same for long. this buffer ensures that our logn and short are calcualted before testing period so we dont have x empty data\n",
    "            #rows and going in blind(unrealistic when historical data is available) \n",
    "\n",
    "            short_df = pd.DataFrame(short_ma, index=adj_test_buffered.index, columns=[etf]) #wrap those into a df again ensuring consistent columns and index\n",
    "            long_df  = pd.DataFrame(long_ma, index=adj_test_buffered.index, columns=[etf])\n",
    "\n",
    "            # Determine last signal from training set\n",
    "            last_train_short = adj_train[etf].rolling(short).mean().iloc[-1]  #finding the last value of short in training period\n",
    "            last_train_long = adj_train[etf].rolling(long).mean().iloc[-1]    #finding the last value of long in training period \n",
    "            initial_position = int(last_train_short > last_train_long * (1 + threshold)) #calculating the boolean (TRUE or FALSE) but the \n",
    "            #int() is turning the TRUE=1 and FALSE=0. so if the last short was greater than the last long multiplied by optimal threshold then \n",
    "            #we are ina  position\n",
    "\n",
    "            # Run strategy on the TESTING SET now with previous position signal \n",
    "            summary = ma_crossover(\n",
    "                etfs=[etf],\n",
    "                log_returns=log_test,\n",
    "                short_ma=short_df,\n",
    "                long_ma=long_df,\n",
    "                threshold=threshold,\n",
    "                initial_position=initial_position  # Must be supported in your function\n",
    "            )\n",
    "\n",
    "            # Store results (test_start buffer already handled inside strategy)\n",
    "            walk_results.append({ #adding new element to list, specifically adding dictionaries(key-value pair)\n",
    "                'Train Start': train_start,\n",
    "                'Train End': train_end,\n",
    "                'Test Start': test_start,\n",
    "                'Test End': test_end,\n",
    "                'ETF': etf,\n",
    "                'Short_MA': short,\n",
    "                'Long_MA': long,\n",
    "                'Threshold': threshold,\n",
    "                'Strategy Return': round(summary.loc[etf, 'Total Strategy Return'], 4),\n",
    "                'Trade Count': int(summary.loc[etf, 'Trade Count']),\n",
    "                'Sharpe': round(summary.loc[etf, 'Sharpe'], 4)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(walk_results) #returning the results as a dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0face1-a2eb-4029-96ee-f57f06422fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = loop_sharp(\n",
    "    adj_close_price=adj_close_price,\n",
    "    log_returns=log_returns,\n",
    "    etfs=['DIA', 'SPY', 'QQQ'],  # or whichever ETFs you're testing\n",
    "    train_years=3,\n",
    "    test_years=2\n",
    ")\n",
    "\n",
    "results_df.to_csv(\"strategy_results_sharpe_based_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced13f43-8605-4c20-b5b1-c93b0ada175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your previously saved walk-forward strategy results\n",
    "results_df = pd.read_csv(\"strategy_results_sharpe_based_final.csv\", parse_dates=['Train Start', 'Train End', 'Test Start', 'Test End'])\n",
    "\n",
    "# Confirm structure\n",
    "print(results_df.head())\n",
    "print(results_df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
